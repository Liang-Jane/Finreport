{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17d162-9cb8-48ee-9095-9f14f7f2547b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U vllm -v --timeout 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3a6e5-0be1-49ff-849f-2f61230a9d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "\n",
    "MODEL_DIR = \"./Qwen2.5-14B-Instruct\"  # Change to your actual model directory (with config.json)\n",
    "\n",
    "from vllm import LLM\n",
    "llm = LLM(\n",
    "    model=MODEL_DIR,\n",
    "    tensor_parallel_size=2,   # You have 2 A800 GPUs, recommended=2; if error occurs, change to 1 first\n",
    "    dtype=\"auto\",\n",
    "    max_model_len=32768,\n",
    ")\n",
    "\n",
    "print(\"llm loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb0939-09b1-4305-85b0-33e5e8906379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install -U pymupdf\n",
    "import sys\n",
    "!{sys.executable} -m pip -q install -U pandas\n",
    "!pip -q install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e52e60-5323-45ec-b603-48c01a6b700d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INPUT_DIR = Path(\"./annual-reports_Microsoft\")   # Directory containing annual report PDFs\n",
    "OUTPUT_DIR = Path(\"./annual-reports_Microsoft_output\")  # Output directory (change to yours)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdf_paths = sorted(INPUT_DIR.glob(\"*.pdf\"))\n",
    "len(pdf_paths), [p.name for p in pdf_paths[:5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59a858-578a-4a9b-815b-4c3674224728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz  # pymupdf\n",
    "\n",
    "def pdf_to_text(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    parts = []\n",
    "    for page in doc:\n",
    "        t = page.get_text(\"text\")\n",
    "        if t and t.strip():\n",
    "            parts.append(t)\n",
    "    return \"\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b880013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Instruction Definitions for Four Prompt Evolution Stages ==========\n",
    "def get_instruction_by_stage(stage: int) -> str:\n",
    "    \"\"\"\n",
    "    Return corresponding instruction based on stage\n",
    "    stage: 1-4, corresponding to four evolution stages\n",
    "    \"\"\"\n",
    "    if stage == 1:\n",
    "        # Stage 1: Simple and direct Baseline Prompt\n",
    "        return \"\"\"Please summarize this annual financial report in English. Output approximately 500 words.\"\"\"\n",
    "    \n",
    "    elif stage == 2:\n",
    "        # Stage 2: Role and Background Setting (Role & Background Alignment)\n",
    "        return \"\"\"You are a professional financial analyst. Please write a financial report summary in English for non-professional investors.\n",
    "\n",
    "Target audience: Non-professional investors who are not familiar with financial terminology and need easy-to-understand explanations.\n",
    "\n",
    "Please summarize this annual financial report in English. Output approximately 500 words.\"\"\"\n",
    "    \n",
    "    elif stage == 3:\n",
    "       # Phase 3: Constraint Conditions and Format Specifications (Constraint-led Prompt)\n",
    "        return \"\"\"You are a professional financial analyst. Please write a financial report summary in English for non-professional investors.\n",
    "\n",
    "Target audience: Non-professional investors who are not familiar with financial terminology and need easy-to-understand explanations.\n",
    "\n",
    "Strict constraints:\n",
    "- Must include risk warnings (Negative News) from the report. If the original text does not mention any risks, clearly state \"Risk information not disclosed in the original report\"\n",
    "- Must include key financial indicators and data\n",
    "- Ensure the summary is objective and comprehensive, without omitting important information\n",
    "- If certain information is not present in the original text, clearly mark it as \"Not disclosed in the original report\"\n",
    "\n",
    "Please summarize this annual financial report in English. Output approximately 500 words.\"\"\"\n",
    "    \n",
    "    elif stage == 4:\n",
    "       #Stage 4: Format Thinking and Popularization Enhancement (CoT & Lay-summary Prompt)\n",
    "        return \"\"\"You are a professional financial analyst. Please write a financial report summary in English for non-professional investors.\n",
    "\n",
    "Target audience: Non-professional investors who are not familiar with financial terminology and need easy-to-understand explanations.\n",
    "\n",
    "Writing process (please follow these steps):\n",
    "Step 1: Identify technical terms - Find professional financial terms in the report (such as \"Deferred Revenue\", \"Goodwill Impairment\", \"EBITDA\", etc.)\n",
    "Step 2: Understand term meanings - Understand the professional meaning and business logic of each term\n",
    "Step 3: Simplify technical terms - Rewrite professional terms into easy-to-understand language (e.g., \"Deferred Revenue\" → \"Customers paid in advance but services haven't been delivered yet\"; \"Goodwill Impairment\" → \"The acquired company is worth less than expected\")\n",
    "Step 4: Logical organization - Understand the logical relationships between data, identify growth points and risk points\n",
    "Step 5: Write the summary - Use simplified language to write an easy-to-understand report summary\n",
    "\n",
    "Strict constraints:\n",
    "- Must include risk warnings (Negative News) from the report. If the original text does not mention any risks, clearly state \"Risk information not disclosed in the original report\"\n",
    "- Must include key financial indicators and data, and explain their meanings in plain language\n",
    "- Ensure the summary is objective and comprehensive, without omitting important information\n",
    "- If certain information is not present in the original text, clearly mark it as \"Not disclosed in the original report\"\n",
    "- Avoid using technical terms. If necessary, explain them in parentheses when first mentioned\n",
    "\n",
    "Please follow the above steps to summarize this annual financial report in English. Output approximately 500 words.\"\"\"\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Stage must be an integer between 1-4, current value: {stage}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc03d2-0b5d-4c94-8eb2-eb8ecd2c4808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import SamplingParams\n",
    "\n",
    "MODEL_DIR = \"./Qwen2.5-14B-Instruct\"  # Change to your model directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "\n",
    "MAX_MODEL_LEN = 32768\n",
    "RESERVE_FOR_OUTPUT = 1500\n",
    "def clean_text(t: str) -> str:\n",
    "\n",
    "    t = unicodedata.normalize(\"NFKC\", t)\n",
    "    t = re.sub(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]\", \" \", t)\n",
    "    t = \"\\n\".join(line for line in t.splitlines() if not re.fullmatch(r\"\\s*\\d+\\s*\", line))\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t\n",
    "\n",
    "def chunk_by_tokens(text, chunk_tokens=6000, overlap_tokens=300):\n",
    "    ids = tokenizer.encode(text)\n",
    "    step = chunk_tokens - overlap_tokens\n",
    "    chunks = []\n",
    "    for start in range(0, len(ids), step):\n",
    "        end = min(start + chunk_tokens, len(ids))\n",
    "        chunks.append(tokenizer.decode(ids[start:end]))\n",
    "        if end >= len(ids):\n",
    "            break\n",
    "    return chunks\n",
    "\n",
    "def build_one_shot_prompt(annual_text: str, instruction: str, stage: int = 1) -> str:\n",
    "    \"\"\"Build one-shot prompt, adjust prefix based on stage\"\"\"\n",
    "    if stage == 1:\n",
    "        # Stage 1: No role setting\n",
    "        prefix = \"\"\n",
    "    elif stage >= 2:\n",
    "        # Stage 2 and above: Include role setting\n",
    "        prefix = \"You are a rigorous financial analyst. You must write reports based only on the given original text.\\n\\n\"\n",
    "    else:\n",
    "        prefix = \"\"\n",
    "    \n",
    "    return f\"\"\"{prefix}Instruction:\n",
    "{instruction}\n",
    "\n",
    "Original Text:\n",
    "{annual_text}\n",
    "\n",
    "IMPORTANT: You MUST write your response entirely in English. Do not use Chinese or any other language. Write the entire summary in English only.\n",
    "\"\"\"\n",
    "def extract_first_json(text: str) -> dict:\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in output\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "def dedup_keep_order(items):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in items:\n",
    "        if not isinstance(x, str):\n",
    "            continue\n",
    "        x2 = x.strip()\n",
    "        if x2 and x2 not in seen:\n",
    "            seen.add(x2)\n",
    "            out.append(x2)\n",
    "    return out\n",
    "\n",
    "def normalize_card(card: dict) -> dict:\n",
    "    for k in [\"facts\", \"major_events\", \"risks\", \"quotes\"]:\n",
    "        if k in card and isinstance(card[k], list):\n",
    "            card[k] = dedup_keep_order(card[k])\n",
    "    return card\n",
    "\n",
    "def build_map_prompts(chunks, stage: int = 1):\n",
    "    \"\"\"Build map stage prompts, adjust requirements based on stage\"\"\"\n",
    "    prompts = []\n",
    "    for i, ch in enumerate(chunks, 1):\n",
    "        if stage <= 2:\n",
    "            # Stage 1 and 2: Basic extraction\n",
    "            risk_instruction = \"risks: 0~5 risk points\"\n",
    "        else:\n",
    "            # Stage 3 and 4: Emphasize must include risk information\n",
    "            risk_instruction = \"risks: 0~5 risk points (must extract, if no risks please mark 'No risks mentioned in this segment')\"\n",
    "        \n",
    "        prompts.append(f\"\"\"\n",
    "You will receive a segment of annual report text. Please strictly extract information only based on the original text, do not fabricate.\n",
    "Output only one JSON object (no markdown, no explanations, no \"please confirm\").\n",
    "Output the JSON marker <END_JSON> immediately after the JSON and stop.\n",
    "\n",
    "JSON fields as follows:\n",
    "- chunk_id: \"c{i:03d}\"\n",
    "- facts: 3~8 key facts (preferably include numbers)\n",
    "- financial_metrics: If financial indicators appear, output as an array, e.g., {{\"name\":\"revenue\",\"value\":\"...\",\"period\":\"...\"}}\n",
    "- major_events: 0~5 major events\n",
    "- {risk_instruction}\n",
    "- quotes: 2~5 short quotes from the original text (to support facts/numbers)\n",
    "\n",
    "Original Text:\n",
    "{ch}\n",
    "<END_JSON>\n",
    "\"\"\".strip())\n",
    "    return prompts\n",
    "\n",
    "\n",
    "def build_reduce_prompt(cards, instruction: str, stage: int = 1) -> str:\n",
    "    \"\"\"Build reduce stage prompt, adjust rules based on stage\"\"\"\n",
    "    if stage == 1:\n",
    "        # Stage 1: Basic rules\n",
    "        rules = \"\"\"Strict rules:\n",
    "- Only use facts/numbers/events that appear in the cards; do not add or guess.\n",
    "- If information is missing, write \"Not disclosed in the original report\".\n",
    "- No repetition: Do not repeat the same sentence/fact.\"\"\"\n",
    "    elif stage == 2:\n",
    "        # Stage 2: Add role and reader perspective\n",
    "        rules = \"\"\"Strict rules:\n",
    "- Only use facts/numbers/events that appear in the cards; do not add or guess.\n",
    "- If information is missing, write \"Not disclosed in the original report\".\n",
    "- Use easy-to-understand language, avoid technical terms, target audience is non-professional investors.\n",
    "- No repetition: Do not repeat the same sentence/fact.\"\"\"\n",
    "    elif stage == 3:\n",
    "        # Stage 3: Emphasize must include risks and key indicators\n",
    "        rules = \"\"\"Strict rules:\n",
    "- Only use facts/numbers/events that appear in the cards; do not add or guess.\n",
    "- Must include risk information: If there are risk warnings in the cards, include all of them; if there is no risk information, clearly state \"Risk information not disclosed in the original report\".\n",
    "- Must include key financial indicators and data.\n",
    "- If other information is missing, write \"Not disclosed in the original report\".\n",
    "- Use easy-to-understand language, avoid technical terms, target audience is non-professional investors.\n",
    "- No repetition: Do not repeat the same sentence/fact.\"\"\"\n",
    "    else:  # stage == 4\n",
    "        # Stage 4: Add popularization requirements\n",
    "        rules = \"\"\"Strict rules:\n",
    "- Only use facts/numbers/events that appear in the cards; do not add or guess.\n",
    "- Must include risk information: If there are risk warnings in the cards, include all of them; if there is no risk information, clearly state \"Risk information not disclosed in the original report\".\n",
    "- Must include key financial indicators and data, and explain their meanings in plain language.\n",
    "- Popularize technical terms: Rewrite technical terms into easy-to-understand language (e.g., \"Deferred Revenue\" → \"Customers paid in advance but services haven't been delivered yet\"; \"Goodwill Impairment\" → \"The acquired company is worth less than expected\").\n",
    "- If other information is missing, write \"Not disclosed in the original report\".\n",
    "- Use easy-to-understand language, target audience is non-professional investors.\n",
    "- No repetition: Do not repeat the same sentence/fact.\"\"\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "You will receive several JSON cards (extracted results from the annual report text).\n",
    "Please strictly follow the Instruction to write the final short report.\n",
    "\n",
    "{rules}\n",
    "\n",
    "Instruction:\n",
    "{instruction}\n",
    "\n",
    "Cards:\n",
    "{chr(10).join(cards)}\n",
    "\n",
    "IMPORTANT: You MUST write your response entirely in English. Do not use Chinese or any other language. Write the entire report summary in English only.\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2bc69a-695b-4d99-9fcc-4240b4eebbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ONE_SHOT_SAMPLING = SamplingParams(\n",
    "    temperature=0.2,\n",
    "    max_tokens=1100,\n",
    "    repetition_penalty=1.08,\n",
    ")\n",
    "\n",
    "MAP_SAMPLING = SamplingParams(\n",
    "    temperature=0.0,\n",
    "    max_tokens=650,              # Don't make it too large, avoid going off track\n",
    "    repetition_penalty=1.15,\n",
    "    stop=[\"<END_JSON>\"],\n",
    ")\n",
    "\n",
    "MAP_RETRY_SAMPLING = SamplingParams(\n",
    "    temperature=0.0,\n",
    "    max_tokens=650,\n",
    "    repetition_penalty=1.25,\n",
    "    stop=[\"<END_JSON>\"],\n",
    ")\n",
    "\n",
    "REDUCE_SAMPLING = SamplingParams(\n",
    "    temperature=0.15,\n",
    "    max_tokens=1200,\n",
    "    repetition_penalty=1.12,\n",
    ")\n",
    "\n",
    "def generate_report_for_text(annual_text: str, llm, instruction: str,\n",
    "                             chunk_tokens=6000, overlap_tokens=300, stage: int = 1):\n",
    "    \"\"\"\n",
    "    Generate report\n",
    "    stage: Prompt evolution stage (1-4)\n",
    "    \"\"\"\n",
    "    total_tokens = len(tokenizer.encode(annual_text))\n",
    "    can_one_shot = total_tokens <= (MAX_MODEL_LEN - RESERVE_FOR_OUTPUT)\n",
    "\n",
    "    if can_one_shot:\n",
    "        prompt = build_one_shot_prompt(annual_text, instruction, stage=stage)\n",
    "        out = llm.generate([prompt], ONE_SHOT_SAMPLING)[0].outputs[0].text\n",
    "        return out, {\"mode\": \"one_shot\", \"total_tokens\": total_tokens, \"chunks\": 0, \"stage\": stage}\n",
    "\n",
    "    chunks = chunk_by_tokens(annual_text, chunk_tokens=chunk_tokens, overlap_tokens=overlap_tokens)\n",
    "    map_prompts = build_map_prompts(chunks, stage=stage)\n",
    "\n",
    "    map_outputs = llm.generate(map_prompts, MAP_SAMPLING)\n",
    "\n",
    "    cards_dicts = []\n",
    "    bad = 0\n",
    "\n",
    "    for idx, o in enumerate(map_outputs, 1):\n",
    "        raw = o.outputs[0].text\n",
    "        try:\n",
    "            card = extract_first_json(raw)\n",
    "        except Exception:\n",
    "            retry_raw = llm.generate([map_prompts[idx-1]], MAP_RETRY_SAMPLING)[0].outputs[0].text\n",
    "            try:\n",
    "                card = extract_first_json(retry_raw)\n",
    "            except Exception:\n",
    "                bad += 1\n",
    "                card = {\n",
    "                    \"chunk_id\": f\"c{idx:03d}\",\n",
    "                    \"facts\": [],\n",
    "                    \"financial_metrics\": [],\n",
    "                    \"major_events\": [],\n",
    "                    \"risks\": [],\n",
    "                    \"quotes\": [],\n",
    "                    \"missing\": [\"Chunk extraction failed\"]\n",
    "                }\n",
    "\n",
    "        card = normalize_card(card)\n",
    "        card.setdefault(\"chunk_id\", f\"c{idx:03d}\")\n",
    "        cards_dicts.append(card)\n",
    "\n",
    "    cards_clean_json = [json.dumps(c, ensure_ascii=False) for c in cards_dicts]\n",
    "\n",
    "    reduce_prompt = build_reduce_prompt(cards_clean_json, instruction, stage=stage)\n",
    "    report = llm.generate([reduce_prompt], REDUCE_SAMPLING)[0].outputs[0].text\n",
    "\n",
    "    return report, {\"mode\": \"map_reduce\", \"total_tokens\": total_tokens, \"chunks\": len(chunks), \"bad_cards\": bad, \"stage\": stage}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6a76a-11f6-4e69-840d-5157ccc8ad77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "# ========== Configuration: Select Stages to Run ==========\n",
    "# Can be set to 1, 2, 3, 4 or [1, 2, 3, 4] to run single or multiple stages\n",
    "STAGES_TO_RUN = [1, 2, 3, 4]  # Run all four stages\n",
    "\n",
    "\n",
    "# Stage name mapping\n",
    "STAGE_NAMES = {\n",
    "    1: \"stage1_baseline\",\n",
    "    2: \"stage2_role_background\", \n",
    "    3: \"stage3_constraints\",\n",
    "    4: \"stage4_cot_laysummary\"\n",
    "}\n",
    "\n",
    "results_all_stages = {}\n",
    "\n",
    "for stage in STAGES_TO_RUN:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting processing stage {stage}: {STAGE_NAMES[stage]}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Get instruction for current stage\n",
    "    instruction = get_instruction_by_stage(stage)\n",
    "    \n",
    "    # Create independent output directory for each stage\n",
    "    stage_output_dir = OUTPUT_DIR / STAGE_NAMES[stage]\n",
    "    stage_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for pdf_path in tqdm(pdf_paths, desc=f\"Stage {stage}\"):\n",
    "        out_txt = stage_output_dir / (pdf_path.stem + \"_short_report.txt\")\n",
    "        out_meta = stage_output_dir / (pdf_path.stem + \"_meta.json\")\n",
    "\n",
    "        # Skip if results already exist (can delete this section to allow overwriting)\n",
    "        if out_txt.exists() and out_meta.exists():\n",
    "            continue\n",
    "\n",
    "        annual_text = clean_text(pdf_to_text(str(pdf_path)))\n",
    "        report, meta = generate_report_for_text(annual_text, llm, instruction, stage=stage)\n",
    "\n",
    "        out_txt.write_text(report, encoding=\"utf-8\")\n",
    "        out_meta.write_text(json.dumps({\"file\": pdf_path.name, **meta}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "        results.append({\"file\": pdf_path.name, **meta})\n",
    "\n",
    "    results_all_stages[stage] = results\n",
    "    print(f\"\\nStage {stage} completed, processed {len(results)} files\\n\")\n",
    "\n",
    "# Display result summary for all stages\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All stages processing completed! Result summary:\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "for stage, results in results_all_stages.items():\n",
    "    print(f\"Stage {stage} ({STAGE_NAMES[stage]}): {len(results)} files\")\n",
    "    if results:\n",
    "        print(f\"  Example: {results[0]['file']} - {results[0]['mode']} - tokens: {results[0]['total_tokens']}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
